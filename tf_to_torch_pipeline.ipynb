{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b26b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from models.tf_models.CifarResnet_tf import get_Resnet18\n",
    "from utils.tf_datasets import get_cifar_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d60f10",
   "metadata": {},
   "source": [
    "# step 1 Load dataset and tf models and test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b93e8",
   "metadata": {},
   "source": [
    "### Note: torch-onnx-tf-onnx is different from tf-onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a5dce",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d549d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_val,y_val,x_test,y_test=get_cifar_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7eea3b",
   "metadata": {},
   "source": [
    "## load model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "710cc698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " build_res_net (BuildResNet)  (None, 10)               11183562  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,183,562\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_Resnet18(num_classes=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a213cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 1446s 18s/step - loss: 1.6081 - accuracy: 0.4480 - val_loss: 9.2747 - val_accuracy: 0.1003\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 1451s 18s/step - loss: 0.9868 - accuracy: 0.6433 - val_loss: 3.5565 - val_accuracy: 0.1118\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 1452s 18s/step - loss: 0.7735 - accuracy: 0.7240 - val_loss: 3.4750 - val_accuracy: 0.1522\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 1462s 19s/step - loss: 0.6009 - accuracy: 0.7883 - val_loss: 2.0553 - val_accuracy: 0.3938\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 1458s 18s/step - loss: 0.4704 - accuracy: 0.8349 - val_loss: 2.0082 - val_accuracy: 0.4537\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 1466s 19s/step - loss: 0.3629 - accuracy: 0.8743 - val_loss: 1.1181 - val_accuracy: 0.6520\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 1457s 18s/step - loss: 0.2759 - accuracy: 0.9029 - val_loss: 1.0556 - val_accuracy: 0.6921\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 1451s 18s/step - loss: 0.2116 - accuracy: 0.9250 - val_loss: 2.3002 - val_accuracy: 0.5847\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 1469s 19s/step - loss: 0.1440 - accuracy: 0.9488 - val_loss: 1.2104 - val_accuracy: 0.7246\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 1458s 18s/step - loss: 0.0975 - accuracy: 0.9656 - val_loss: 1.2081 - val_accuracy: 0.7255\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 1500s 19s/step - loss: 0.0963 - accuracy: 0.9660 - val_loss: 1.4460 - val_accuracy: 0.7224\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 1444s 18s/step - loss: 0.0958 - accuracy: 0.9664 - val_loss: 2.3951 - val_accuracy: 0.6079\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 1439s 18s/step - loss: 0.0557 - accuracy: 0.9806 - val_loss: 1.4103 - val_accuracy: 0.7211\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 1438s 18s/step - loss: 0.0431 - accuracy: 0.9845 - val_loss: 1.2223 - val_accuracy: 0.7675\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 1441s 18s/step - loss: 0.0543 - accuracy: 0.9811 - val_loss: 1.4058 - val_accuracy: 0.7415\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 1445s 18s/step - loss: 0.0688 - accuracy: 0.9759 - val_loss: 1.7614 - val_accuracy: 0.7045\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=20\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data = (x_val, y_val), batch_size=512,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa85b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 67s 847ms/step - loss: 1.8803 - accuracy: 0.6891\n",
      "test loss, test acc: [1.8803019523620605, 0.6891000270843506]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733329e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as .hs file\n",
    "save_path = \"saved_models/tf2torch/CifarResnet18.h5\"\n",
    "model.save(save_path)\n",
    "# save as saved_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795afd05",
   "metadata": {},
   "source": [
    "# step 2 convert from tensorflow to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266d1b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnxruntime as rt\n",
    "\n",
    "\n",
    "spec = (tf.TensorSpec((None, 32, 32, 3), tf.float32, name=\"input\"),)\n",
    "output_path = \"saved_models/tf2torch/CifarResnet18_from_keras.onnx\"\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=output_path)\n",
    "output_names = [n.name for n in model_proto.graph.output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d9ee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['build_res_net']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6135ac2",
   "metadata": {},
   "source": [
    "# step 3 test onnx model using onnxruntime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0467e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "load_path_1 = \"saved_models/tf2torch/CifarResnet18_from_keras.onnx\"\n",
    "onnx_model_1 = onnx.load(load_path_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a24ef6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.checker.check_model(onnx_model_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9cc1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ort_sess):\n",
    "    _correct=0\n",
    "    _all=y_test.shape[0]\n",
    "    batch_size=256\n",
    "    num_batches = _all//batch_size\n",
    "    for i in range(num_batches):\n",
    "        if i!=num_batches-1:\n",
    "            output=ort_sess.run(output_names=output_names,input_feed={\"input\":x_test[i*batch_size:(i+1)*batch_size]})\n",
    "            pred = np.argmax(output[0],axis=1).reshape(-1,1)\n",
    "            _correct+=(pred==y_test[i*batch_size:(i+1)*batch_size]).sum()\n",
    "            \n",
    "        else:\n",
    "            output=ort_sess.run(output_names=output_names,input_feed={\"input\":x_test[i*batch_size:]})\n",
    "            pred = np.argmax(output[0],axis=1).reshape(-1,1)\n",
    "            _correct+=(pred==y_test[i*batch_size:]).sum()\n",
    "    return _correct/_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8c489e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of onnx model from tf: 0.6891\n"
     ]
    }
   ],
   "source": [
    "ort_sess_1 = ort.InferenceSession('saved_models/tf2torch/CifarResnet18_from_keras.onnx')\n",
    "#ort_sess_2 = ort.InferenceSession('saved_models/torch2tf/CifarResnet18.onnx')\n",
    "# Print accuracy Result\n",
    "acc_1 = get_accuracy(ort_sess_1)\n",
    "#acc_2 = get_accuracy(ort_sess_2)\n",
    "print(f\"accuracy of onnx model from tf: {acc_1}\")\n",
    "#print(f\"accuracy of onnx model from torch: {acc_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20add32",
   "metadata": {},
   "source": [
    "# step 4 convert onnx to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9bb7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx2pytorch import ConvertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d1a3652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stephen\\Anaconda3\\envs\\practice\\lib\\site-packages\\onnx2pytorch\\convert\\layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n",
      "C:\\Users\\Stephen\\Anaconda3\\envs\\practice\\lib\\site-packages\\onnx2pytorch\\convert\\model.py:147: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvertModel(\n",
       "  (Transpose_model/build_res_net/conv2d/Conv2D__6:0): Transpose()\n",
       "  (Conv_model/build_res_net/batch_normalization/FusedBatchNormV3:0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_model/build_res_net/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential/basic_block/batch_normalization_1/FusedBatchNormV3:0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_model/build_res_net/sequential/basic_block/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential/basic_block/batch_normalization_2/FusedBatchNormV3:0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_model/build_res_net/sequential/basic_block/add/add:0): Add()\n",
       "  (Relu_model/build_res_net/sequential/basic_block/Relu_1:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential/basic_block_1/batch_normalization_3/FusedBatchNormV3:0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_model/build_res_net/sequential/basic_block_1/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential/basic_block_1/batch_normalization_4/FusedBatchNormV3:0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_model/build_res_net/sequential/basic_block_1/add_1/add:0): Add()\n",
       "  (Relu_model/build_res_net/sequential/basic_block_1/Relu_1:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_2/basic_block_2/sequential_1/batch_normalization_7/FusedBatchNormV3:0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Conv_model/build_res_net/sequential_2/basic_block_2/batch_normalization_5/FusedBatchNormV3:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (Relu_model/build_res_net/sequential_2/basic_block_2/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_2/basic_block_2/batch_normalization_6/FusedBatchNormV3:0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_model/build_res_net/sequential_2/basic_block_2/add_2/add:0): Add()\n",
       "  (Relu_model/build_res_net/sequential_2/basic_block_2/Relu_1:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_2/basic_block_3/batch_normalization_8/FusedBatchNormV3:0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_model/build_res_net/sequential_2/basic_block_3/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_2/basic_block_3/batch_normalization_9/FusedBatchNormV3:0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_model/build_res_net/sequential_2/basic_block_3/add_3/add:0): Add()\n",
       "  (Relu_model/build_res_net/sequential_2/basic_block_3/Relu_1:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_4/basic_block_4/sequential_3/batch_normalization_12/FusedBatchNormV3:0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Conv_model/build_res_net/sequential_4/basic_block_4/batch_normalization_10/FusedBatchNormV3:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (Relu_model/build_res_net/sequential_4/basic_block_4/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_4/basic_block_4/batch_normalization_11/FusedBatchNormV3:0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_model/build_res_net/sequential_4/basic_block_4/add_4/add:0): Add()\n",
       "  (Relu_model/build_res_net/sequential_4/basic_block_4/Relu_1:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_4/basic_block_5/batch_normalization_13/FusedBatchNormV3:0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_model/build_res_net/sequential_4/basic_block_5/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_4/basic_block_5/batch_normalization_14/FusedBatchNormV3:0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_model/build_res_net/sequential_4/basic_block_5/add_5/add:0): Add()\n",
       "  (Relu_model/build_res_net/sequential_4/basic_block_5/Relu_1:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_6/basic_block_6/sequential_5/batch_normalization_17/FusedBatchNormV3:0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Conv_model/build_res_net/sequential_6/basic_block_6/batch_normalization_15/FusedBatchNormV3:0): Sequential(\n",
       "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0)\n",
       "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (Relu_model/build_res_net/sequential_6/basic_block_6/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_6/basic_block_6/batch_normalization_16/FusedBatchNormV3:0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_model/build_res_net/sequential_6/basic_block_6/add_6/add:0): Add()\n",
       "  (Relu_model/build_res_net/sequential_6/basic_block_6/Relu_1:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_6/basic_block_7/batch_normalization_18/FusedBatchNormV3:0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_model/build_res_net/sequential_6/basic_block_7/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_model/build_res_net/sequential_6/basic_block_7/batch_normalization_19/FusedBatchNormV3:0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_model/build_res_net/sequential_6/basic_block_7/add_7/add:0): Add()\n",
       "  (Relu_model/build_res_net/sequential_6/basic_block_7/Relu_1:0): ReLU(inplace=True)\n",
       "  (AveragePool_model/build_res_net/average_pooling2d/AvgPool:0): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=0)\n",
       "  (Reshape_model/build_res_net/flatten/Reshape:0): Reshape(shape=[ -1 512])\n",
       "  (MatMul_model/build_res_net/dense/BiasAdd:0): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (Softmax_build_res_net): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model = ConvertModel(onnx_model_1,debug=False,experimental=True)\n",
    "torch_model.eval()\n",
    "torch_model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c21de",
   "metadata": {},
   "source": [
    "# step 5 test torch model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "daa10f70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_call' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m==\u001b[39mlabel:\n\u001b[0;32m      8\u001b[0m         _correct\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_correct\u001b[38;5;241m/\u001b[39m\u001b[43m_call\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_call' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "_all=len(y_test)\n",
    "_correct=0\n",
    "for img,label in zip(x_test,y_test):\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    out=torch.argmax(torch_model(img)).item()\n",
    "    if out==label:\n",
    "        _correct+=1\n",
    "print(f\"accuracy: {_correct/_call}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
