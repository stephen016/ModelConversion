{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b26b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from models.tf_models.CifarResnet_tf import get_CifarResnet18\n",
    "from models.tf_models.tf_models import tf_resnet50,tf_densenet121,tf_inception_resnet_v2, tf_resnet18\n",
    "from utils.tf_datasets import get_cifar_data,get_imagenette_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97448b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d60f10",
   "metadata": {},
   "source": [
    "# step 1 Load dataset and tf models and test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b93e8",
   "metadata": {},
   "source": [
    "### Note: torch-onnx-tf-onnx is different from tf-onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a5dce",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d549d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar\n",
    "#x_train,y_train,x_val,y_val,x_test,y_test=get_cifar_data()\n",
    "# imagenette\n",
    "train_ds,val_ds,test_ds = get_imagenette_data(batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7eea3b",
   "metadata": {},
   "source": [
    "## load model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce577ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf_resnet50(num_classes=10,retrain=False)\n",
    "model = tf_resnet18(num_classes=10)\n",
    "#model = tf_densenet121(num_classes=10,retrain=False)\n",
    "#model = tf_inception_resnet_v2(num_classes=10,retrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cc698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = get_Resnet18(num_classes=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "#history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data = (x_val, y_val), batch_size=128,callbacks=[callback])\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=3,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa85b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "#results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "results = model.evaluate(test_ds)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733329e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as .hs file\n",
    "save_path = \"saved_models/tf2torch/resnet18.h5\"\n",
    "#save_path = \"saved_models/tf2torch/resnet50.h5\"\n",
    "#save_path = \"saved_models/tf2torch/densenet121.h5\"\n",
    "#save_path = \"saved_models/tf2torch/inception_resnet_v2.h5\"\n",
    "model.save(save_path)\n",
    "# save as saved_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795afd05",
   "metadata": {},
   "source": [
    "# step 2 convert from tensorflow to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d1b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnxruntime as rt\n",
    "\n",
    "spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32, name=\"input\"),)\n",
    "#output_path = \"saved_models/tf2torch/resnet50.onnx\"\n",
    "#output_path = \"saved_models/tf2torch/densenet121.onnx\"\n",
    "#output_path = \"saved_models/tf2torch/inception_resnet_v2.onnx\"\n",
    "output_path = \"saved_models/tf2torch/resnet18.onnx\"\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=output_path)\n",
    "output_names = [n.name for n in model_proto.graph.output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d9ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6135ac2",
   "metadata": {},
   "source": [
    "# step 3 test onnx model using onnxruntime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0467e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "load_path_onnx = \"saved_models/tf2torch/resnet50.onnx\"\n",
    "#load_path_onnx = \"saved_models/tf2torch/densenet121.onnx\"\n",
    "#load_path_onnx = \"saved_models/tf2torch/inception_resnet_v2.onnx\"\n",
    "#load_path_onnx = \"saved_models/tf2torch/resnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path_onnx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ef6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.checker.check_model(onnx_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for cifar10\n",
    "def get_accuracy(ort_sess):\n",
    "    _correct=0\n",
    "    _all=y_test.shape[0]\n",
    "    batch_size=256\n",
    "    num_batches = _all//batch_size\n",
    "    for i in range(num_batches):\n",
    "        if i!=num_batches-1:\n",
    "            output=ort_sess.run(output_names=output_names,input_feed={\"input\":x_test[i*batch_size:(i+1)*batch_size]})\n",
    "            pred = np.argmax(output[0],axis=1).reshape(-1,1)\n",
    "            _correct+=(pred==y_test[i*batch_size:(i+1)*batch_size]).sum()\n",
    "            \n",
    "        else:\n",
    "            output=ort_sess.run(output_names=output_names,input_feed={\"input\":x_test[i*batch_size:]})\n",
    "            pred = np.argmax(output[0],axis=1).reshape(-1,1)\n",
    "            _correct+=(pred==y_test[i*batch_size:]).sum()\n",
    "    return _correct/_all\n",
    "\"\"\"\n",
    "# for imagenette\n",
    "def get_accuracy(ort_sess):\n",
    "    _correct = 0\n",
    "    _all = 0\n",
    "    for imgs, labels in test_ds:\n",
    "        _all+=len(labels)\n",
    "        labels = np.argmax(labels,axis=1).reshape(-1,1)\n",
    "        output=ort_sess.run(output_names=output_names,input_feed={\"input\":imgs.numpy()})\n",
    "        pred = np.argmax(output[0],axis=1).reshape(-1,1)\n",
    "        _correct+= (labels==pred).sum()\n",
    "    #print(f\"accuracy of onnx model: {_correct/_all}\")\n",
    "    return _correct/_all\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c489e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ort_sess = ort.InferenceSession('saved_models/tf2torch/resnet50.onnx')\n",
    "#ort_sess = ort.InferenceSession('saved_models/tf2torch/densenet121.onnx')\n",
    "#ort_sess = ort.InferenceSession('saved_models/tf2torch/inception_resnet_v2.onnx')\n",
    "ort_sess = ort.InferenceSession('saved_models/tf2torch/resnet18.onnx')\n",
    "# Print accuracy Result\n",
    "onnx_acc = get_accuracy(ort_sess)\n",
    "\n",
    "print(f\"accuracy of onnx model from tf: {onnx_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20add32",
   "metadata": {},
   "source": [
    "# step 4 convert onnx to torch and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42931b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx2torch import convert\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd71bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reduce batch_size\n",
    "train_ds,val_ds,test_ds = get_imagenette_data(batch_size=8)\n",
    "load_path_onnx = \"saved_models/tf2torch/resnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path_onnx)\n",
    "pytorch_model = convert(onnx_model)\n",
    "pytorch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_correct=0\n",
    "_all=0\n",
    "for imgs,labels in test_ds:\n",
    "    _all+=len(labels)\n",
    "    labels=np.argmax(labels,axis=1)\n",
    "    out=pytorch_model(torch.from_numpy(imgs.numpy()))\n",
    "    pred = torch.argmax(out,axis=1).numpy()\n",
    "    _correct+=(pred==labels).sum()\n",
    "print(f\"pytorch model acc: {_correct/_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893131f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test training converted torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad27ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train torch model\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "learning_rate = 1e-2\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self,model):\n",
    "        super(LitModel,self).__init__()\n",
    "        self.model=model\n",
    "        self.test_acc = torchmetrics.Accuracy()\n",
    "        self.valid_acc = torchmetrics.Accuracy()\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),lr=learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        images, labels = batch\n",
    "        images = images.permute(0,2,3,1)\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return {\"loss\":loss}\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        images, labels = batch\n",
    "        images = images.permute(0,2,3,1)\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        self.valid_acc(outputs, labels)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\",self.valid_acc)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def test_step(self,batch,batch_idx):\n",
    "        images, labels = batch\n",
    "        images = images.permute(0,2,3,1)\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        self.test_acc(outputs, labels)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log('test_acc', self.test_acc)\n",
    "        return {\"test_loss\":loss}\n",
    "    \n",
    "    def validation_epoch_end(self,outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\":avg_loss}\n",
    "\n",
    "        return {\"val_lss\":avg_loss,\"log\":tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "train_model = LitModel(pytorch_model)\n",
    "epochs=1\n",
    "from utils.data_loaders import get_imagenette_loader\n",
    "train_loader,val_loader,test_loader = get_imagenette_loader(batch_size=4)\n",
    "\n",
    "trainer = Trainer(max_epochs=epochs,fast_dev_run=True,accelerator=\"cpu\")\n",
    "\n",
    "trainer.fit(train_model,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db3010",
   "metadata": {},
   "source": [
    "# step 5 Convert onnx model back to tf models and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a3652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf\n",
    "import onnx_tf\n",
    "load_path_onnx = \"saved_models/tf2torch/resnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path_onnx)\n",
    "tf_rep = prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load\n",
    "save_path = \"saved_models/tf2torch/resnet18\"\n",
    "tf_rep.export_graph(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded=tf.saved_model.load(save_path)\n",
    "print(list(loaded.signatures.keys())) \n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "key=list(infer.structured_outputs.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d89256",
   "metadata": {},
   "outputs": [],
   "source": [
    "_all=0\n",
    "_correct=0\n",
    "for imgs,labels in test_ds:\n",
    "    out = infer(**{'input': imgs})\n",
    "    pred = np.argmax(out[key],axis=1)\n",
    "    _all+=len(labels)\n",
    "    _correct+=(pred==labels.numpy()).sum()\n",
    "print(f\"accuracy:{_correct/_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba70f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
