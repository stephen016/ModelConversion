{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0be8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 10:53:03.017990: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-23 10:53:04.026639: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-23 10:53:07.189152: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-23 10:53:07.189650: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-23 10:53:07.189666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "from models.torch_models.torch_models import resnet18\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from utils.data_loaders import get_cifar_loader,get_imagenette_loader\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import onnxruntime as ort\n",
    "from onnx2pytorch import ConvertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae0c2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu117\n",
      "use device: cuda\n",
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "# check torch version and device\n",
    "print(torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"use device:\",device)\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c0aa9",
   "metadata": {},
   "source": [
    "# step 1 load pytorch model dataloader and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf836409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/wangxun/miniconda3/envs/MA/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#train_loader,val_loader,test_loader = get_cifar_loader(batch_size=2)\n",
    "train_loader,val_loader,test_loader = get_imagenette_loader(batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b9153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | model     | ResNet   | 11.2 M\n",
      "1 | test_acc  | Accuracy | 0     \n",
      "2 | valid_acc | Accuracy | 0     \n",
      "---------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "running\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99641bcbd9a54b0b8d99f8d5455526f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs=3\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_acc\", min_delta=0.00, patience=5, verbose=False, mode=\"max\")\n",
    "\n",
    "trainer = Trainer(max_epochs=epochs,fast_dev_run=False,accelerator=\"gpu\",callbacks=[early_stop_callback])\n",
    "model = resnet18(num_classes=10).to(device)\n",
    "\n",
    "trainer.fit(model,train_loader,val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb414522",
   "metadata": {},
   "source": [
    "# step 2 test pytorch model accuracy and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a2255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9554fa88beb546a3a17d5fa53300f510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.7864000201225281\r\n",
      "        test_loss           0.9610121250152588\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.9610121250152588, 'test_acc': 0.7864000201225281}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "01e81284",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = model.model\n",
    "save_path = \"saved_models/torch2tf/CifarResnet18.pth\"\n",
    "torch.save(torch_model.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90f2ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8144000172615051\n"
     ]
    }
   ],
   "source": [
    "# check if saved model is correct\n",
    "load_path = \"saved_models/torch2tf/resnet18.pth\"\n",
    "model2 = resnet18(num_classes=10).model\n",
    "model2.load_state_dict(torch.load(load_path))\n",
    "model2.eval()\n",
    "model2=model2.to(device)\n",
    "_all=0\n",
    "_correct=0\n",
    "for imgs,labels in test_loader:\n",
    "    pred = torch.argmax(model2(imgs.to(device)),axis=1).to(\"cpu\")\n",
    "    _all+=len(labels)\n",
    "    _correct+=(pred==labels).sum()\n",
    "print(f\"accuracy:{_correct/_all}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef30fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also save the whole model\n",
    "full_model_save_path = \"saved_models/torch2tf/CifarResnet18_model.pth\"\n",
    "torch.save(model2,full_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f58700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0133c797",
   "metadata": {},
   "source": [
    "# step 3 convert pytorch model to onnx model and test onnx model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "85d02e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1,3,32,32,device=\"cuda\")\n",
    "save_path = \"saved_models/torch2tf/CifarResnet18.onnx\"\n",
    "\n",
    "torch.onnx.export(model2,\n",
    "                  dummy_input,\n",
    "                  save_path,\n",
    "                  input_names=[\"input\"],\n",
    "                  output_names=[\"output\"],\n",
    "                  dynamic_axes={'input':{0:'batch_size'}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d40108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of onnx model from torch: 0.8144\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(ort_sess):\n",
    "    _correct=0\n",
    "    _all=0\n",
    "    for imgs,labels in test_loader:\n",
    "        output = ort_sess.run(output_names=['output'],input_feed={'input': imgs.numpy()})\n",
    "        pred = np.argmax(output[0],axis=1)\n",
    "        _all+=len(labels)\n",
    "        _correct+=(pred==labels.numpy()).sum()\n",
    "    return _correct/_all\n",
    "ort_sess = ort.InferenceSession('saved_models/torch2tf/CifarResnet18.onnx')\n",
    "acc = get_accuracy(ort_sess)\n",
    "print(f\"accuracy of onnx model from torch: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdc57c",
   "metadata": {},
   "source": [
    "# step 4 convert onnx model to tf model test accuracy and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "36919c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"saved_models/torch2tf/CifarResnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path)\n",
    "tf_rep = prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "19d12145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8144\n"
     ]
    }
   ],
   "source": [
    "_all=0\n",
    "_correct=0\n",
    "for imgs,labels in test_loader:\n",
    "    pred = np.argmax(tf_rep.run(imgs)[0],axis=1)\n",
    "    _all+=len(labels)\n",
    "    _correct+=(pred==labels.numpy()).sum()\n",
    "print(f\"accuracy:{_correct/_all}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "4680b3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/torch2tf/CifarResnet18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/torch2tf/CifarResnet18\\assets\n"
     ]
    }
   ],
   "source": [
    "save_path = \"saved_models/torch2tf/CifarResnet18\"\n",
    "tf_rep.export_graph(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b35f8",
   "metadata": {},
   "source": [
    "# step 5 load tf model and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4e6e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"saved_models/torch2tf/CifarResnet18\"\n",
    "loaded=tf.saved_model.load(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "7a0fd481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n"
     ]
    }
   ],
   "source": [
    "print(list(loaded.signatures.keys())) \n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "key=list(infer.structured_outputs.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c0b7f76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8144\n"
     ]
    }
   ],
   "source": [
    "_all=0\n",
    "_correct=0\n",
    "for imgs,labels in test_loader:\n",
    "    out = infer(**{'input': imgs})\n",
    "    pred = np.argmax(out[key],axis=1)\n",
    "    _all+=len(labels)\n",
    "    _correct+=(pred==labels.numpy()).sum()\n",
    "print(f\"accuracy:{_correct/_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "51892644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.654736  -7.450909  -4.149689  -2.9547741 -2.7491271  1.6382511\n",
      "  -8.316099  10.531688  -8.481063  -4.960392 ]]\n",
      "[[-6.654734  -7.450907  -4.1496887 -2.9547796 -2.749123   1.638253\n",
      "  -8.316097  10.531686  -8.481064  -4.96039  ]]\n"
     ]
    }
   ],
   "source": [
    "# additional test one single sample if they produce same result\n",
    "test_img=imgs[0].unsqueeze(0)\n",
    "model2.eval()\n",
    "out1=model2(test_img.to(device)).cpu()\n",
    "out2=infer(**{'input': test_img})[key]\n",
    "print(out1.detach().numpy())\n",
    "print(out2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb345cfa",
   "metadata": {},
   "source": [
    "# step 6 convert onnx model back to torch model and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86056117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stephen\\Anaconda3\\envs\\practice\\lib\\site-packages\\onnx2pytorch\\convert\\layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n"
     ]
    }
   ],
   "source": [
    "load_path = \"saved_models/torch2tf/CifarResnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path)\n",
    "torch_model = ConvertModel(onnx_model,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "195d8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_converted_pytorch_model(model):\n",
    "    _all=0\n",
    "    _correct=0\n",
    "    for imgs,labels in test_loader:\n",
    "        _all+=len(labels)\n",
    "        for img,label in zip(imgs,labels):\n",
    "            output = model(img.unsqueeze(0))\n",
    "            _correct+=(torch.argmax(output)==label).item()\n",
    "    return _correct/_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6215f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.8144\n"
     ]
    }
   ],
   "source": [
    "acc=get_acc_from_converted_pytorch_model(torch_model)\n",
    "print(f\"acc:{acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8023f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6853502988815308\n"
     ]
    }
   ],
   "source": [
    "# use onnx2torch\n",
    "from onnx2torch import convert\n",
    "load_path = \"saved_models/torch2tf/resnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path)\n",
    "torch_model_2 = convert(load_path).to(device)\n",
    "_correct=0\n",
    "_all=0\n",
    "for (img,labels) in test_loader:\n",
    "    _all+=len(labels)\n",
    "    out=torch_model_2(img.to(device)).to(\"cpu\")\n",
    "    pred = torch.argmax(out,axis=1)\n",
    "    _correct+=(pred==labels).sum()\n",
    "print(f\"accuracy: {_correct/_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bb78b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
