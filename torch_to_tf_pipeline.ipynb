{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0be8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "from models.torch_models.torch_models import resnet18\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from utils.data_loaders import get_cifar_loader,get_imagenette_loader\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import onnx_tf\n",
    "import onnxruntime as ort\n",
    "from onnx2pytorch import ConvertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check torch version and device\n",
    "print(torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"use device:\",device)\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c0aa9",
   "metadata": {},
   "source": [
    "# step 1 load pytorch model dataloader and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf836409",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_loader,val_loader,test_loader = get_cifar_loader(batch_size=64)\n",
    "#train_loader,val_loader,test_loader = get_imagenette_loader(batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b9153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs=3\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_acc\", min_delta=0.00, patience=5, verbose=False, mode=\"max\")\n",
    "\n",
    "trainer = Trainer(max_epochs=epochs,fast_dev_run=False,accelerator=\"gpu\",callbacks=[early_stop_callback])\n",
    "model = resnet18(num_classes=10).to(device)\n",
    "\n",
    "trainer.fit(model,train_loader,val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb414522",
   "metadata": {},
   "source": [
    "# step 2 test pytorch model accuracy and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e81284",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = model.model\n",
    "save_path = \"saved_models/torch2tf/CifarResnet18.pth\"\n",
    "torch.save(torch_model.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if saved model is correct\n",
    "load_path = \"saved_models/torch2tf/resnet18.pth\"\n",
    "model2 = resnet18(num_classes=10).model\n",
    "model2.load_state_dict(torch.load(load_path))\n",
    "model2.eval()\n",
    "model2=model2.to(device)\n",
    "_all=0\n",
    "_correct=0\n",
    "for imgs,labels in test_loader:\n",
    "    pred = torch.argmax(model2(imgs.to(device)),axis=1).to(\"cpu\")\n",
    "    _all+=len(labels)\n",
    "    _correct+=(pred==labels).sum()\n",
    "print(f\"accuracy:{_correct/_all}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef30fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also save the whole model\n",
    "full_model_save_path = \"saved_models/torch2tf/CifarResnet18_model.pth\"\n",
    "torch.save(model2,full_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f58700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0133c797",
   "metadata": {},
   "source": [
    "# step 3 convert pytorch model to onnx model and test onnx model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d02e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1,3,32,32,device=\"cuda\")\n",
    "save_path = \"saved_models/torch2tf/CifarResnet18.onnx\"\n",
    "\n",
    "torch.onnx.export(model2,\n",
    "                  dummy_input,\n",
    "                  save_path,\n",
    "                  input_names=[\"input\"],\n",
    "                  output_names=[\"output\"],\n",
    "                  dynamic_axes={'input':{0:'batch_size'}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d40108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ort_sess):\n",
    "    _correct=0\n",
    "    _all=0\n",
    "    for imgs,labels in test_loader:\n",
    "        output = ort_sess.run(output_names=['output'],input_feed={'input': imgs.numpy()})\n",
    "        pred = np.argmax(output[0],axis=1)\n",
    "        _all+=len(labels)\n",
    "        _correct+=(pred==labels.numpy()).sum()\n",
    "    return _correct/_all\n",
    "ort_sess = ort.InferenceSession('saved_models/torch2tf/CifarResnet18.onnx')\n",
    "acc = get_accuracy(ort_sess)\n",
    "print(f\"accuracy of onnx model from torch: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdc57c",
   "metadata": {},
   "source": [
    "# step 4 convert onnx model to tf model test accuracy and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36919c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"saved_models/torch2tf/CifarResnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path)\n",
    "tf_rep = prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d12145",
   "metadata": {},
   "outputs": [],
   "source": [
    "_all=0\n",
    "_correct=0\n",
    "for imgs,labels in test_loader:\n",
    "    pred = np.argmax(tf_rep.run(imgs)[0],axis=1)\n",
    "    _all+=len(labels)\n",
    "    _correct+=(pred==labels.numpy()).sum()\n",
    "print(f\"accuracy:{_correct/_all}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"saved_models/torch2tf/CifarResnet18\"\n",
    "tf_rep.export_graph(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d61b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test training converted tf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02beec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep = onnx_tf.backend.prepare(onnx_model,training_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_compat = tf.compat.v1\n",
    "epochs=1\n",
    "training_flag_placeholder = tf_rep.tensor_dict[\n",
    "    onnx_tf.backend.training_flag_name]\n",
    "input_name = onnx_model.graph.input[0].name\n",
    "output_name = onnx_model.graph.output[0].name\n",
    "\n",
    "with tf_rep.graph.as_default():\n",
    "    with tf_compat.Session() as sess:\n",
    "        y_truth = tf_compat.placeholder(tf.int64, [None], name='y-input')\n",
    "        tf_rep.tensor_dict[\"y_truth\"] = y_truth\n",
    "        loss_op = tf.reduce_mean(\n",
    "            tf_compat.losses.sparse_softmax_cross_entropy(\n",
    "                labels=tf_rep.tensor_dict['y_truth'],\n",
    "                logits=tf_rep.tensor_dict[output_name]))\n",
    "        opt_op = tf_compat.train.AdamOptimizer().minimize(loss_op)\n",
    "        eval_op = tf.reduce_mean(input_tensor=tf.cast(\n",
    "            tf.equal(tf.argmax(input=tf_rep.tensor_dict[output_name], axis=1),\n",
    "            tf_rep.tensor_dict['y_truth']), tf.float32))\n",
    "        x_train,y_train,x_val,y_val,x_test,y_test = get_cifar_data()\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "        sess.run(tf_compat.global_variables_initializer())\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            step = 1\n",
    "            next_batch = tf_compat.data.make_one_shot_iterator(train_ds).get_next()\n",
    "            while True:\n",
    "                try:\n",
    "                    next_batch_value = sess.run(next_batch)\n",
    "                    feed_dict = {\n",
    "                        tf_rep.tensor_dict[input_name]: next_batch_value[0].transpose((0, 3, 1, 2)),#for pytorch model\n",
    "                        #tf_rep.tensor_dict[input_name]:next_batch_value[0],\n",
    "                        tf_rep.tensor_dict['y_truth']:next_batch_value[1].flatten()\n",
    "                                }\n",
    "                    feed_dict[training_flag_placeholder] = True\n",
    "                    loss, accuracy, _ = sess.run([loss_op, eval_op, opt_op],feed_dict=feed_dict)\n",
    "                    print('Epoch {}, train step {}, loss:{}, accuracy:{}'.format(epoch, step, loss, accuracy))\n",
    "                    step += 1\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    step = 1\n",
    "                    break\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b35f8",
   "metadata": {},
   "source": [
    "# step 5 load tf model and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"saved_models/torch2tf/CifarResnet18\"\n",
    "loaded=tf.saved_model.load(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fd481",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(loaded.signatures.keys())) \n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "key=list(infer.structured_outputs.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b7f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_all=0\n",
    "_correct=0\n",
    "for imgs,labels in test_loader:\n",
    "    out = infer(**{'input': imgs})\n",
    "    pred = np.argmax(out[key],axis=1)\n",
    "    _all+=len(labels)\n",
    "    _correct+=(pred==labels.numpy()).sum()\n",
    "print(f\"accuracy:{_correct/_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51892644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional test one single sample if they produce same result\n",
    "test_img=imgs[0].unsqueeze(0)\n",
    "model2.eval()\n",
    "out1=model2(test_img.to(device)).cpu()\n",
    "out2=infer(**{'input': test_img})[key]\n",
    "print(out1.detach().numpy())\n",
    "print(out2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb345cfa",
   "metadata": {},
   "source": [
    "# step 6 convert onnx model back to torch model and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86056117",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"saved_models/torch2tf/CifarResnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path)\n",
    "torch_model = ConvertModel(onnx_model,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_converted_pytorch_model(model):\n",
    "    _all=0\n",
    "    _correct=0\n",
    "    for imgs,labels in test_loader:\n",
    "        _all+=len(labels)\n",
    "        for img,label in zip(imgs,labels):\n",
    "            output = model(img.unsqueeze(0))\n",
    "            _correct+=(torch.argmax(output)==label).item()\n",
    "    return _correct/_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6215f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=get_acc_from_converted_pytorch_model(torch_model)\n",
    "print(f\"acc:{acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use onnx2torch\n",
    "from onnx2torch import convert\n",
    "load_path = \"saved_models/torch2tf/CifarResnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path)\n",
    "torch_model_2 = convert(onnx_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8023f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "_correct=0\n",
    "_all=0\n",
    "for (img,labels) in test_loader:\n",
    "    _all+=len(labels)\n",
    "    out=torch_model_2(img.to(device)).to(\"cpu\")\n",
    "    pred = torch.argmax(out,axis=1)\n",
    "    _correct+=(pred==labels).sum()\n",
    "print(f\"accuracy: {_correct/_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train torch model\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "learning_rate = 1e-2\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self,model):\n",
    "        super(LitModel,self).__init__()\n",
    "        self.model=model\n",
    "        self.test_acc = torchmetrics.Accuracy()\n",
    "        self.valid_acc = torchmetrics.Accuracy()\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),lr=learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return {\"loss\":loss}\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        self.valid_acc(outputs, labels)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\",self.valid_acc)\n",
    "        return {\"val_loss\":loss}\n",
    "\n",
    "    def test_step(self,batch,batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        self.test_acc(outputs, labels)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log('test_acc', self.test_acc)\n",
    "        return {\"test_loss\":loss}\n",
    "    \n",
    "    def validation_epoch_end(self,outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\":avg_loss}\n",
    "\n",
    "        return {\"val_lss\":avg_loss,\"log\":tensorboard_logs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = LitModel(torch_model_2)\n",
    "epochs=1\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_acc\", min_delta=0.00, patience=5, verbose=False, mode=\"max\")\n",
    "\n",
    "trainer = Trainer(max_epochs=epochs,fast_dev_run=False,accelerator=\"gpu\",callbacks=[early_stop_callback])\n",
    "\n",
    "trainer.fit(train_model,train_loader,val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9fc164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
