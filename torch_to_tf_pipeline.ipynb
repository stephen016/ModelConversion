{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0be8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "from models.torch_models.torch_models import resnet18\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from utils.data_loaders import get_cifar_loader,get_imagenette_loader\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import onnxruntime as ort\n",
    "from onnx2pytorch import ConvertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae0c2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu116\n",
      "use device: cuda\n",
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "# check torch version and device\n",
    "print(torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"use device:\",device)\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c0aa9",
   "metadata": {},
   "source": [
    "# step 1 load pytorch model dataloader and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf836409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_loader,val_loader,test_loader = get_cifar_loader(batch_size=2)\n",
    "#train_loader,val_loader,test_loader = get_imagenette_loader(batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b9153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | model     | ResNet   | 11.2 M\n",
      "1 | test_acc  | Accuracy | 0     \n",
      "2 | valid_acc | Accuracy | 0     \n",
      "---------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "running\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99641bcbd9a54b0b8d99f8d5455526f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs=3\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_acc\", min_delta=0.00, patience=5, verbose=False, mode=\"max\")\n",
    "\n",
    "trainer = Trainer(max_epochs=epochs,fast_dev_run=False,accelerator=\"gpu\",callbacks=[early_stop_callback])\n",
    "model = resnet18(num_classes=10).to(device)\n",
    "\n",
    "trainer.fit(model,train_loader,val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb414522",
   "metadata": {},
   "source": [
    "# step 2 test pytorch model accuracy and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a2255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9554fa88beb546a3a17d5fa53300f510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.7864000201225281\r\n",
      "        test_loss           0.9610121250152588\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.9610121250152588, 'test_acc': 0.7864000201225281}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "01e81284",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = model.model\n",
    "save_path = \"saved_models/torch2tf/CifarResnet18.pth\"\n",
    "torch.save(torch_model.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90f2ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8144000172615051\n"
     ]
    }
   ],
   "source": [
    "# check if saved model is correct\n",
    "load_path = \"saved_models/torch2tf/CifarResnet18.pth\"\n",
    "model2 = resnet18(num_classes=10).model\n",
    "model2.load_state_dict(torch.load(load_path))\n",
    "model2.eval()\n",
    "model2=model2.to(device)\n",
    "_all=0\n",
    "_correct=0\n",
    "for imgs,labels in test_loader:\n",
    "    pred = torch.argmax(model2(imgs.to(device)),axis=1).to(\"cpu\")\n",
    "    _all+=len(labels)\n",
    "    _correct+=(pred==labels).sum()\n",
    "print(f\"accuracy:{_correct/_all}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef30fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also save the whole model\n",
    "full_model_save_path = \"saved_models/torch2tf/CifarResnet18_model.pth\"\n",
    "torch.save(model2,full_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f58700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0133c797",
   "metadata": {},
   "source": [
    "# step 3 convert pytorch model to onnx model and test onnx model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "85d02e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1,3,32,32,device=\"cuda\")\n",
    "save_path = \"saved_models/torch2tf/CifarResnet18.onnx\"\n",
    "\n",
    "torch.onnx.export(model2,\n",
    "                  dummy_input,\n",
    "                  save_path,\n",
    "                  input_names=[\"input\"],\n",
    "                  output_names=[\"output\"],\n",
    "                  dynamic_axes={'input':{0:'batch_size'}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d40108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of onnx model from torch: 0.8144\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(ort_sess):\n",
    "    _correct=0\n",
    "    _all=0\n",
    "    for imgs,labels in test_loader:\n",
    "        output = ort_sess.run(output_names=['output'],input_feed={'input': imgs.numpy()})\n",
    "        pred = np.argmax(output[0],axis=1)\n",
    "        _all+=len(labels)\n",
    "        _correct+=(pred==labels.numpy()).sum()\n",
    "    return _correct/_all\n",
    "ort_sess = ort.InferenceSession('saved_models/torch2tf/CifarResnet18.onnx')\n",
    "acc = get_accuracy(ort_sess)\n",
    "print(f\"accuracy of onnx model from torch: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdc57c",
   "metadata": {},
   "source": [
    "# step 4 convert onnx model to tf model test accuracy and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "36919c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"saved_models/torch2tf/CifarResnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path)\n",
    "tf_rep = prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "19d12145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8144\n"
     ]
    }
   ],
   "source": [
    "_all=0\n",
    "_correct=0\n",
    "for imgs,labels in test_loader:\n",
    "    pred = np.argmax(tf_rep.run(imgs)[0],axis=1)\n",
    "    _all+=len(labels)\n",
    "    _correct+=(pred==labels.numpy()).sum()\n",
    "print(f\"accuracy:{_correct/_all}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "4680b3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/torch2tf/CifarResnet18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/torch2tf/CifarResnet18\\assets\n"
     ]
    }
   ],
   "source": [
    "save_path = \"saved_models/torch2tf/CifarResnet18\"\n",
    "tf_rep.export_graph(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b35f8",
   "metadata": {},
   "source": [
    "# step 5 load tf model and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4e6e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"saved_models/torch2tf/CifarResnet18\"\n",
    "loaded=tf.saved_model.load(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "7a0fd481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n"
     ]
    }
   ],
   "source": [
    "print(list(loaded.signatures.keys())) \n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "key=list(infer.structured_outputs.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c0b7f76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8144\n"
     ]
    }
   ],
   "source": [
    "_all=0\n",
    "_correct=0\n",
    "for imgs,labels in test_loader:\n",
    "    out = infer(**{'input': imgs})\n",
    "    pred = np.argmax(out[key],axis=1)\n",
    "    _all+=len(labels)\n",
    "    _correct+=(pred==labels.numpy()).sum()\n",
    "print(f\"accuracy:{_correct/_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "51892644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.654736  -7.450909  -4.149689  -2.9547741 -2.7491271  1.6382511\n",
      "  -8.316099  10.531688  -8.481063  -4.960392 ]]\n",
      "[[-6.654734  -7.450907  -4.1496887 -2.9547796 -2.749123   1.638253\n",
      "  -8.316097  10.531686  -8.481064  -4.96039  ]]\n"
     ]
    }
   ],
   "source": [
    "# additional test one single sample if they produce same result\n",
    "test_img=imgs[0].unsqueeze(0)\n",
    "model2.eval()\n",
    "out1=model2(test_img.to(device)).cpu()\n",
    "out2=infer(**{'input': test_img})[key]\n",
    "print(out1.detach().numpy())\n",
    "print(out2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb345cfa",
   "metadata": {},
   "source": [
    "# step 6 convert onnx model back to torch model and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86056117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stephen\\Anaconda3\\envs\\practice\\lib\\site-packages\\onnx2pytorch\\convert\\layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n"
     ]
    }
   ],
   "source": [
    "load_path = \"saved_models/torch2tf/CifarResnet18.onnx\"\n",
    "onnx_model = onnx.load(load_path)\n",
    "torch_model = ConvertModel(onnx_model,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "195d8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_converted_pytorch_model(model):\n",
    "    _all=0\n",
    "    _correct=0\n",
    "    for imgs,labels in test_loader:\n",
    "        _all+=len(labels)\n",
    "        for img,label in zip(imgs,labels):\n",
    "            output = model(img.unsqueeze(0))\n",
    "            _correct+=(torch.argmax(output)==label).item()\n",
    "    return _correct/_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6215f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.8144\n"
     ]
    }
   ],
   "source": [
    "acc=get_acc_from_converted_pytorch_model(torch_model)\n",
    "print(f\"acc:{acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8023f275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
